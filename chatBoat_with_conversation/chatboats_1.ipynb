{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a chatboat with conversation history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x72082624e510>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x72082624f020>, model_name='Gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model = ChatGroq(model='Gemma2-9b-it', groq_api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Kamal,\\n\\nIt's nice to meet you! That's a fascinating title - Chief AI Engineer. What kind of exciting projects are you working on?  \\n\\nI'm eager to hear more about your work in the field of AI.  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 56, 'prompt_tokens': 24, 'total_tokens': 80, 'completion_time': 0.101818182, 'prompt_time': 0.000143429, 'queue_time': 0.013907299, 'total_time': 0.101961611}, 'model_name': 'Gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-697fd9eb-640d-4d5e-80c3-7d1527416555-0', usage_metadata={'input_tokens': 24, 'output_tokens': 56, 'total_tokens': 80})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model.invoke([HumanMessage(content=\"Hii my name is kamal i am a chief enginner of ai.\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You are Kamal Jit Singh, and you are the Chief Engineer of AI.  \\n\\nIs there anything else you'd like to know or discuss? 😊 \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 35, 'prompt_tokens': 112, 'total_tokens': 147, 'completion_time': 0.063636364, 'prompt_time': 0.005375635, 'queue_time': 0.035190404999999994, 'total_time': 0.069011999}, 'model_name': 'Gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-8cedddf6-1446-4e32-b23b-ef5376bb2952-0', usage_metadata={'input_tokens': 112, 'output_tokens': 35, 'total_tokens': 147})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "model.invoke([\n",
    "    HumanMessage(content=\"Hii my name is kamal jit singh i am chief engineer of AI\"),\n",
    "    AIMessage(content=\"Hello Kamal! It's great to meet you. \\n\\nBeing a chief engineer of AI is a fascinating role. What kind of projects are you working on?  What are some of the challenges and rewards you find in your work?  \\n\\nI'm always eager to learn more about the advancements being made in the field of AI\"),\n",
    "    HumanMessage(content=\"Hey what is my name nad what do i do?\")\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Message history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id:str)-> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "## create a configuration for session_id\n",
    "config = {\"configurable\": {\"session_id\": \"chat1\"}}\n",
    "\n",
    "## creaete a runnableiwth message history\n",
    "with_message_history = RunnableWithMessageHistory(model, get_session_history)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hii my name is kamal and i am chief ai engineer.\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Kamal! It's nice to meet you. That's a fascinating title!  \\n\\nWhat kind of AI projects are you working on these days? I'm always eager to learn more about what people are doing in the field. 😊  \\n\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Your name is Kamal.  \\n\\nI remember our introduction! It's nice to chat with you. 😊  \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 89, 'total_tokens': 115, 'completion_time': 0.047272727, 'prompt_time': 0.00237679, 'queue_time': 0.01219135, 'total_time': 0.049649517}, 'model_name': 'Gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-681b1f78-fda5-4376-90e0-3f45529dde0f-0', usage_metadata={'input_tokens': 89, 'output_tokens': 26, 'total_tokens': 115})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name ?\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## changing the config : changing the config session_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As an AI, I have no memory of past conversations and do not know your name. If you'd like to tell me, I'd be happy to use it! 😊\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 15, 'total_tokens': 55, 'completion_time': 0.072727273, 'prompt_time': 8.7269e-05, 'queue_time': 0.015274661, 'total_time': 0.072814542}, 'model_name': 'Gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-c2793b8c-c960-46e2-8ad2-6daeaa3911f4-0', usage_metadata={'input_tokens': 15, 'output_tokens': 40, 'total_tokens': 55})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## i have changed session_id and it has returned it has not memory of the past\n",
    "config = {\"configurable\": {\"session_id\": \"chat2\"}}\n",
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"hey what is my name?\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## with changing session_id chat2 i will query \n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hey my name is chanda and i am a commerce student and dreamed to became a IAM officer?\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Chanda, it's nice to meet you! \\n\\nThat's a great dream! Being an IAM (Identity and Access Management) Officer is a really exciting field, especially with your background in commerce.  \\n\\nDo you have any specific questions about IAM or how your commerce studies might help you achieve your goal? I'd be happy to chat more about it.  \\n\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hey what is my name and what do i do?\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are Chanda, and you are a commerce student who dreams of becoming an IAM (Identity and Access Management) Officer!  \\n\\nIs there anything else you'd like to talk about regarding your dream career?  I'm here to help! 😊  \\n\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## with changing session_id chat2 i will query \n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hey my name is chanda and i am a commerce student and dreamed to became a IAM officer?\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As an AI, I have no memory of past conversations and do not know your name. If you'd like to tell me your name, I'd be happy to know! 😊\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 15, 'total_tokens': 56, 'completion_time': 0.074545455, 'prompt_time': 9.0079e-05, 'queue_time': 0.015064021, 'total_time': 0.074635534}, 'model_name': 'Gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-6fda3898-1592-49aa-a30e-a42613c81845-0', usage_metadata={'input_tokens': 15, 'output_tokens': 41, 'total_tokens': 56})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## i have changed session_id and it has returned it has not memory of the past\n",
    "config1 = {\"configurable\": {\"session_id\": \"cha3\"}}\n",
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"hey what is my name?\")],\n",
    "    config=config1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with prompt templets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpfull assistant. Answer all the queations to the nest of your ability.\"),\n",
    "    MessagesPlaceholder(variable_name=\"message\")\n",
    "])\n",
    "\n",
    "\n",
    "chain = prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Kamal, it's nice to meet you!\\n\\nI'm happy to help with any questions you have.  What can I do for you today? 😊  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 34, 'total_tokens': 73, 'completion_time': 0.070909091, 'prompt_time': 0.000313127, 'queue_time': 0.014767251, 'total_time': 0.071222218}, 'model_name': 'Gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-2fa40757-bb25-4561-aa35-dfd4a6240fc6-0', usage_metadata={'input_tokens': 34, 'output_tokens': 39, 'total_tokens': 73})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"message\": [HumanMessage(content=\"Hey my name is kamal\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Durga, it's nice to meet you!  \\n\\nCongratulations on graduating with a degree in maths! That's a fantastic achievement.  \\n\\nWhat can I help you with today?  Do you have any questions about maths, or are you looking for something else?  \\n\\nI'm here to assist in any way I can. 😊 \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 76, 'prompt_tokens': 41, 'total_tokens': 117, 'completion_time': 0.138181818, 'prompt_time': 0.001663627, 'queue_time': 0.015560682999999999, 'total_time': 0.139845445}, 'model_name': 'Gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-60fb48bd-106f-44b8-9523-66f602d979ce-0', usage_metadata={'input_tokens': 41, 'output_tokens': 76, 'total_tokens': 117})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": 'chat3'}}\n",
    "\n",
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hey my name is durga and i am graduated with maths.\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You told me your name is Durga, and you graduated with a degree in mathematics! \\n\\nAs we're just meeting, I don't know what you do now. Would you like to tell me?  😊  I'm always happy to learn new things. \\n\\n\\n\\n\\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 61, 'prompt_tokens': 352, 'total_tokens': 413, 'completion_time': 0.110909091, 'prompt_time': 0.011727333, 'queue_time': 0.004108515, 'total_time': 0.122636424}, 'model_name': 'Gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-bac418d6-e527-4e07-b596-b1fde892440a-0', usage_metadata={'input_tokens': 352, 'output_tokens': 61, 'total_tokens': 413})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"hey what is my name and what do i do?\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add more complexity with chat prompt\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Hey you are a helpfull assistend. Answer all the question based on your ability in {language}\"),\n",
    "    MessagesPlaceholder(variable_name=\"message\")    \n",
    "])\n",
    "\n",
    "chain = prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"message\": [HumanMessage(content=\"Hey my name is kamal.\")], \"language\":\"Hindi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'नमस्ते कमल! 👋 \\n\\nमैं आपकी मदद करने के लिए तैयार हूँ। आप मुझसे कोई भी प्रश्न पूछें, मैं अपनी क्षमताओं के अनुसार जवाब देने की पूरी कोशिश करूंगा। 😊 \\n\\nआप क्या जानना चाहते हैं? 🤔\\n\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## invoke with message history with session id\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"message\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"chat4\"}}\n",
    "response = with_message_history.invoke(\n",
    "    {\"message\": HumanMessage(content=\"Hey my name is kamal and i am a chief engineer of Ai.\"), \"language\": \"Hindi\"},\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'नमस्ते कमल जी! \\n\\nमुझे जानकर बहुत खुशी हुई कि आप एआई के मुख्य इंजीनियर हैं।  आपकी भूमिका बहुत ही दिलचस्प है! \\n\\n  क्या मैं आपकी मदद करने में कुछ भी कर सकता हूँ? आप किस बारे में बात करना चाहते हैं? \\n\\n'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managing conversation history\n",
    "- `trimmer messages`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a good assistant.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I like vanila ice cream', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='nice.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='what 2+2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problems', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having funs', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, trim_messages\n",
    "\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=45,\n",
    "    strategy='last',\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on='human'\n",
    ")\n",
    "\n",
    "## set of messages\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a good assistant.\"),\n",
    "    HumanMessage(content=\"hii i am kamal\"),\n",
    "    AIMessage(content=\"hii\"),\n",
    "    HumanMessage(content=\"I like vanila ice cream\"),\n",
    "    AIMessage(content=\"nice.\"),\n",
    "    HumanMessage(content=\"what 2+2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"Thanks\"),\n",
    "    AIMessage(content=\"no problems\"),\n",
    "    HumanMessage(content=\"having funs\"),\n",
    "    AIMessage(content=\"yes\"),\n",
    "]\n",
    "\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
